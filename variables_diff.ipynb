{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gedzhMOMPhED2teXsKLF4-FVO3cqJYSB",
      "authorship_tag": "ABX9TyMVa9gkYezPr42taSt7o+iI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mansivyas26/perfusion_dataPipeline/blob/main/variables_diff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ACxMkMSV9O3M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import ast\n",
        "import warnings\n",
        "from pandas_gbq import to_gbq\n",
        "from google.cloud import storage\n",
        "from google.cloud import bigquery\n",
        "\n",
        "import pickle\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pickle_from_gcs(bucket_name):\n",
        "    try:\n",
        "        # Initialize a client\n",
        "        key_path = '/content/drive/MyDrive/Pefusion_DataPipeline/platform-developement-dev-env-7a2997352c88.json'\n",
        "        client = storage.Client.from_service_account_json(key_path)\n",
        "\n",
        "        # Get the bucket\n",
        "        bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "        # List all blobs (files) in the bucket\n",
        "        blobs = bucket.list_blobs()\n",
        "\n",
        "        # Iterate over each blob\n",
        "        for blob in blobs:\n",
        "            # Check if the blob is a file and its name is \"all_data.pkl\"\n",
        "            if blob.name.endswith('.pkl') and blob.name.split('/')[-1] == 'all_data.pkl':\n",
        "                # Download the file\n",
        "                content = blob.download_as_string()\n",
        "\n",
        "                # Load the pickle object from the downloaded content\n",
        "                pickle_object = pickle.loads(content)\n",
        "\n",
        "                # Convert the pickle object to a DataFrame\n",
        "                df = pd.DataFrame(pickle_object)\n",
        "\n",
        "                return df\n",
        "\n",
        "        # If no file named \"all_data.pkl\" is found\n",
        "        print(\"File 'all_data.pkl' not found in the bucket.\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "bucket_name = \"your_bucket_name\"\n",
        "df = download_pickle_from_gcs(bucket_name)\n",
        "if df is not None:\n",
        "    print(\"DataFrame successfully loaded from 'all_data.pkl'.\")\n",
        "else:\n",
        "    print(\"Failed to load DataFrame.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IbZIUlDO3hH",
        "outputId": "4cafa563-a071-4f53-d335-edbdc1f271f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 403 GET https://storage.googleapis.com/storage/v1/b/your_bucket_name?projection=noAcl&prettyPrint=false: platform-developement-dev-env@appspot.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist).\n",
            "Failed to load DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-storage\n"
      ],
      "metadata": {
        "id": "2xGz8BlYTrp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = \"mark2_runs_bex_ds_dev/Steve/BEXT104_02-23-2024_11-47-53\"\n",
        "file_name = \"all_data.pkl\"\n",
        "pickle_object = download_pickle_from_gcs(bucket_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "vdAfMaFnQTpS",
        "outputId": "d958d70f-3e55-4a99-b549-3fce935bec45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFound",
          "evalue": "404 GET https://storage.googleapis.com/storage/v1/b/mark2_runs_bex_ds_dev/Steve/BEXT104_02-23-2024_11-47-53?projection=noAcl&prettyPrint=false: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-088fadf18796>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbucket_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mark2_runs_bex_ds_dev/Steve/BEXT104_02-23-2024_11-47-53\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all_data.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_pickle_from_gcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-6c048b7c6532>\u001b[0m in \u001b[0;36mdownload_pickle_from_gcs\u001b[0;34m(bucket_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Get the bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# List all blobs (files) in the bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/storage/client.py\u001b[0m in \u001b[0;36mget_bucket\u001b[0;34m(self, bucket_or_name, timeout, if_metageneration_match, if_metageneration_not_match, retry)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \"\"\"\n\u001b[1;32m    781\u001b[0m         \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bucket_arg_to_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_or_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         bucket.reload(\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/storage/bucket.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self, client, projection, timeout, if_etag_match, if_etag_not_match, if_metageneration_match, if_metageneration_not_match, retry)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mHow\u001b[0m \u001b[0mto\u001b[0m \u001b[0mretry\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mRPC\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSee\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mconfiguring_retries\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \"\"\"\n\u001b[0;32m-> 1082\u001b[0;31m         super(Bucket, self).reload(\n\u001b[0m\u001b[1;32m   1083\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/storage/_helpers.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self, client, projection, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, retry)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_etag_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_etag_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_etag_not_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_etag_not_match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         )\n\u001b[0;32m--> 246\u001b[0;31m         api_response = client._get_resource(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/storage/client.py\u001b[0m in \u001b[0;36m_get_resource\u001b[0;34m(self, path, query_params, headers, timeout, retry, _target_object)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \"\"\"\n\u001b[0;32m--> 387\u001b[0;31m         return self._connection.api_request(\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/storage/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 GET https://storage.googleapis.com/storage/v1/b/mark2_runs_bex_ds_dev/Steve/BEXT104_02-23-2024_11-47-53?projection=noAcl&prettyPrint=false: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read individual runs file .pkl from bigquery\n",
        "perfusion_data = pd.read_pickle(\"/content/drive/MyDrive/Steve_BEXT84_01-17-2024_13-56-14_all_data.pkl\")"
      ],
      "metadata": {
        "id": "Px1ophy5-N9x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read variable dictionary\n",
        "variable_dict = pd.read_csv(\"/content/drive/MyDrive/Pefusion_DataPipeline/test_262.02 - test.csv\")\n",
        "\n",
        "variable_dict['possible_variables'] = variable_dict['possible_variables'].apply(ast.literal_eval)\n",
        "#variable_dict.to_csv(\"/content/drive/MyDrive/Pefusion_DataPipeline/test.csv\")\n"
      ],
      "metadata": {
        "id": "DFYUo-YwQOVv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the existing schema\n",
        "schema = pd.read_csv(\"/content/drive/MyDrive/Pefusion_DataPipeline/m12_full_join.csv\",nrows=10)"
      ],
      "metadata": {
        "id": "f5yj61upCFvF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perfusion_data_subset = perfusion_data.head(3)"
      ],
      "metadata": {
        "id": "oefOecUbFCkU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check scehma with variable dictionary and renames the column if needed to standard_variable\n",
        "def check_schema(schema,variable_dict):\n",
        "  columns = schema.columns.tolist()\n",
        "  for column in columns:\n",
        "        match_found = False\n",
        "        for idx, row in variable_dict.iterrows():\n",
        "            if column in row['possible_variables']:\n",
        "                match_found = True\n",
        "                if column != row['standard_variable']:\n",
        "                    print(\"columns that were renamed\",column)\n",
        "                    schema.rename(columns={column: row['standard_variable']}, inplace=True)"
      ],
      "metadata": {
        "id": "jYXEx7oGnlK-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function call\n",
        "check_schema(schema,variable_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcLRQwGiqwhH",
        "outputId": "11433e6f-ba6f-4307-839f-8e9a8207ebb0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns that were renamed glucose_control_mode\n",
            "columns that were renamed syringe_pump_manual_setrate\n",
            "columns that were renamed time\n",
            "columns that were renamed probe_ph_mv_measured\n",
            "columns that were renamed glucose_pump_rate_setpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def check_columns(df):\n",
        "  val = 'None'\n",
        "  if val in df.columns:\n",
        "      # Drop the column named 'None'\n",
        "      df = df.drop(columns=[val])\n"
      ],
      "metadata": {
        "id": "1iwiiTtxx7eq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_columns(perfusion_data_subset)"
      ],
      "metadata": {
        "id": "setYf4U3yDaI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_columns(schema)"
      ],
      "metadata": {
        "id": "MtQYCcK2yG7m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compare .pkl file , variable dicitionary and Schema\n",
        "\n",
        "def check_runs_with_variable_dict_new(pkl_df, variable_dict, schema_subset):\n",
        "\n",
        "    removed_columns = []  # List to keep track of REMOVED columns\n",
        "    list_of_files_ignored_in_pkl = ['timestamp','glucose_syringe_pump_buzzer']\n",
        "    list_of_files_ignored_in_schema = ['resistance_qc_solenoid_flag','perfusion_date','perfusion_id','control_time','glucose_syringe_pump_dispensed_control', 'glucose_syringe_pump_buzzer_control']\n",
        "\n",
        "    temporary_none = ['dialysis_compensate_scale_weight','dialysis_flux_valve_position','viscometer_temperature','dialysis_post_pressure','dialysis_compensate_pump_rate','dialysis_compensate_scale_flux','dialysis_pre_pressure','dialysis_pre_pressure_setpoint','dialysis_pressure_valve_position','dialysis_waste_scale_flux','dialysis_waste_scale_weight','']\n",
        "    #list of variables to be added in schema\n",
        "    for idx, row in variable_dict.iterrows():\n",
        "            if row['standard_variable'] in list_of_files_ignored_in_schema:\n",
        "                  pkl_df[row['standard_variable']] = \"to be added\"\n",
        "    columns = pkl_df.columns.tolist()\n",
        "    for column in columns:\n",
        "        match_found = False\n",
        "        for idx, row in variable_dict.iterrows():\n",
        "           if column in row['possible_variables']:\n",
        "                match_found = True\n",
        "                if row['variable_status'] == \"EXISTING\" and column != row['standard_variable']:\n",
        "                    pkl_df.rename(columns={column: row['standard_variable']}, inplace=True)\n",
        "                    if column in schema_subset.columns:\n",
        "                        schema_subset.rename(columns={column: row['standard_variable']}, inplace=True)\n",
        "                elif row['variable_status'] == \"NEW\":\n",
        "                    #add a column with name row['standard_variable'] and  value = None\n",
        "                    variable_dict.loc[idx,'variable_status'] = \"EXISTING\"\n",
        "                  #rename to standard variable\n",
        "                    if row['standard_variable'] not in schema_subset.columns:\n",
        "                        schema_subset[row['standard_variable']] = None\n",
        "\n",
        "                elif row['variable_status'] == \"REMOVED\":\n",
        "                   # print(f\"Removed column identified: {column}\")\n",
        "                    removed_columns.append(column)\n",
        "                    for c in removed_columns:\n",
        "                      print(removed_columns)\n",
        "                      pkl_df[c] = None\n",
        "\n",
        "\n",
        "           if not match_found:\n",
        "              if row['variable_status'] == \"REMOVED\":\n",
        "               pkl_df[column] = \"removed\"\n",
        "              for val in temporary_none:\n",
        "                if val in schema_subset.columns and val not in pkl_df.columns:\n",
        "        # Add a new column to the pkl DataFrame with the value initialized as None\n",
        "                 pkl_df[val] = \"None\"\n",
        "\n",
        "\n",
        "    cols_to_drop = list(set(pkl_df.columns).intersection(set(list_of_files_ignored_in_pkl)))\n",
        "    print(cols_to_drop)\n",
        "    pkl_df = pkl_df.drop(cols_to_drop,inplace=True,axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O9DGDd8fFWZD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_columns_match(df1, df2):\n",
        "    columns_df1 = set(df1.columns)\n",
        "    columns_df2 = set(df2.columns)\n",
        "\n",
        "    if columns_df1 != columns_df2:\n",
        "        columns_only_in_df1 = columns_df1 - columns_df2\n",
        "        columns_only_in_df2 = columns_df2 - columns_df1\n",
        "\n",
        "        print(\"Columns only in .pkl file:\", columns_only_in_df1)\n",
        "        print(\"Columns only in schema:\", columns_only_in_df2)\n",
        "        print(len(columns_only_in_df2),\"only_schema\")\n",
        "        print(len(columns_only_in_df1),\"only_pkl\")\n",
        "\n",
        "        return False\n",
        "    else:\n",
        "        print(len(df1.columns),\"pkl\")\n",
        "        print(len(df2.columns),\"schema\")\n",
        "        print(\"Columns match between the two DataFrames.\")\n",
        "        return True\n",
        "\n",
        "def append_df_row_wise(pkl_df, schema_df):\n",
        "    #pkl_df = pkl_df.drop(columns=['None'],inplace=True)\n",
        "\n",
        "    # Check if columns match\n",
        "    if not check_columns_match(pkl_df, schema_df):\n",
        "      return None\n",
        "    else:\n",
        "      schema_df = schema_df[sorted(schema_df.columns)]\n",
        "      pkl_df = pkl_df[sorted(pkl_df.columns)]\n",
        "      #print(pkl_df)\n",
        "\n",
        "      \"\"\"schema_df.reset_index(drop=True, inplace=True)\n",
        "      schema_duplicates = schema_df.index.duplicated()\n",
        "      print(\"schema\",schema_df[schema_duplicates])\n",
        "      pkl_df.reset_index(drop=True,inplace=True)\"\"\"\n",
        "\n",
        "      combined_df = schema_df.append(pkl_df,ignore_index=True)\n",
        "      #combined_df.to_csv(\"/content/drive/MyDrive/Pefusion_DataPipeline/combined.csv\")\n",
        "      #print(combined_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "2cl-bKVl7Jto"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(append_df_row_wise(perfusion_data_subset,schema))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is6yS-LAxxK0",
        "outputId": "4132f84d-1675-43aa-c85f-1d7d3196fd0a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132 pkl\n",
            "132 schema\n",
            "Columns match between the two DataFrames.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(check_runs_with_variable_dict_new(perfusion_data_subset,variable_dict,schema))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBcdqz3TWnd4",
        "outputId": "bb801de2-bbbc-4208-f4a5-4cbe51e6cf54"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['control_time']\n",
            "['control_time', 'glucose_syringe_pump_buzzer_control']\n",
            "['control_time', 'glucose_syringe_pump_buzzer_control']\n",
            "[]\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "my_list = perfusion_data_subset.columns.to_list()  # Example list\n",
        "\n",
        "# Count occurrences of each element\n",
        "counts = Counter(my_list)\n",
        "\n",
        "# Find duplicate values\n",
        "duplicates = [item for item, count in counts.items() if count > 1]\n",
        "\n",
        "print(\"Duplicate values:\", duplicates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Fwgk05wGqm",
        "outputId": "612b0150-da01-4742-d3f4-3aaa918e401f"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate values: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perfusion_data_subset['glucose_syringe_pump_volume_setpoint']"
      ],
      "metadata": {
        "id": "z-r7p0cwyZPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicate_columns_func(df):\n",
        "  duplicate_columns = df.columns[df.columns.duplicated()]\n",
        "  print(duplicate_columns)\n",
        "\n",
        "  # Drop just one duplicate column\n",
        "  if duplicate_columns.any():\n",
        "      column_to_drop = duplicate_columns[0]  # Select the first duplicate column to drop\n",
        "      df.drop(columns=column_to_drop, inplace=True)\n",
        "      print(\"Duplicate column dropped:\", column_to_drop)\n",
        "  else:\n",
        "      print(\"No duplicate columns found.\")\n",
        "\n",
        "  print(\"DataFrame after dropping duplicate column:\")\n",
        "  print(df)"
      ],
      "metadata": {
        "id": "v-bmvmWZ0PFU"
      },
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6aHudUt0XMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['glucose_syringe_pump_volume_setpoint', 'syringe_pump_volume_setpoint', 'glucose_pump_rate_automatic_setpoint']\n",
        "list2 = schema.columns.to_list()\n",
        "list3 = perfusion_data_subset.columns.to_list()"
      ],
      "metadata": {
        "id": "G6plQhq_E5NE"
      },
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_matching_values(list1, list2):\n",
        "    return list(set(list1) & set(list2))"
      ],
      "metadata": {
        "id": "0PHBtvzuFO1X"
      },
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_matching_values(list1,list3)\n",
        "#find_matching_values(glucose_syringe_pump_volume_setpoint,glucose_syringe_pump_hour_setrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sJfz9p4FP3q",
        "outputId": "c15ad8b6-6066-4b04-acb9-04a09684209d"
      },
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['syringe_pump_volume_setpoint', 'glucose_pump_rate_automatic_setpoint']"
            ]
          },
          "metadata": {},
          "execution_count": 467
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_table_and_load_df(project_id, dataset_id, table_id, df):\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    dataset_ref = client.dataset(dataset_id)\n",
        "\n",
        "    # Create dataset if it doesn't exist\n",
        "    dataset = bigquery.Dataset(dataset_ref)\n",
        "    if not client.get_dataset(dataset_ref, retry=None):\n",
        "        dataset = client.create_dataset(dataset)\n",
        "\n",
        "    table_ref = dataset_ref.table(table_id)\n",
        "\n",
        "    # Check if the table exists\n",
        "    try:\n",
        "        table = client.get_table(table_ref)\n",
        "    except NotFound:\n",
        "        # Define the schema based on the DataFrame\n",
        "        schema = [bigquery.SchemaField(column, 'STRING') for column in df.columns]\n",
        "\n",
        "        # Create the table with the specified schema\n",
        "        table = bigquery.Table(table_ref, schema=schema)\n",
        "        table = client.create_table(table)\n",
        "\n",
        "    # Load the DataFrame into the table\n",
        "    job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "    client.load_table_from_dataframe(df, table_ref, job_config=job_config).result()\n",
        "\n",
        "    print(f'Data loaded into BigQuery table {project_id}.{dataset_id}.{table_id}.')\n"
      ],
      "metadata": {
        "id": "luMz91BjHYtI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'platform-developement-dev-env'\n",
        "dataset_id = 'dataConsistency_test'\n",
        "table_id = 'BEXT84_updated'\n",
        "\n",
        "# Call the function to create the table (if it doesn't exist) and load the DataFrame\n",
        "create_table_and_load_df(project_id, dataset_id, table_id, perfusion_data_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "7YAj-RccSerk",
        "outputId": "d5fa208f-3bc7-4649-9580-f76b833d81c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RefreshError",
          "evalue": "(\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7da4a9724700>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTransportError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             self.token, self.expiry = _metadata.get_service_account_token(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\u001b[0m in \u001b[0;36m_retrieve_info\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         info = _metadata.get_service_account_info(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_account_email\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\u001b[0m in \u001b[0;36mget_service_account_info\u001b[0;34m(request, service_account)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# for more on the use of 'recursive'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"recursive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(request, path, root, params, recursive, retry_count, headers, return_none_for_not_found_error)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     raise exceptions.TransportError(\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;34m\"Failed to retrieve {} from the Google Compute Engine \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTransportError\u001b[0m: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7da4a9724700>)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRefreshError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9bee274a8782>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Call the function to create the table (if it doesn't exist) and load the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcreate_table_and_load_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperfusion_data_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-7de549944e09>\u001b[0m in \u001b[0;36mcreate_table_and_load_df\u001b[0;34m(project_id, dataset_id, table_id, df)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Create dataset if it doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self, dataset_ref, retry, timeout)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         api_response = self._call_api(\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.getDataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             ):\n\u001b[0;32m--> 816\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         response = self._make_request(\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, url, data, content_type, headers, target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         return self._do_request(\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36m_do_request\u001b[0;34m(self, method, url, headers, data, target_object, timeout)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mHTTP\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[0;32m--> 379\u001b[0;31m         return self.http.request(\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0mremaining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\u001b[0m in \u001b[0;36mbefore_request\u001b[0;34m(self, request, method, url, headers)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_metric_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric_header_for_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\u001b[0m in \u001b[0;36m_blocking_refresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_blocking_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_non_blocking_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_exc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mnew_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefreshError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaught_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcaught_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRefreshError\u001b[0m: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7da4a9724700>)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OoFRe9F-SNZB"
      }
    }
  ]
}